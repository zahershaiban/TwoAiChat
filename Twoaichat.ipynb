{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "# Tokens\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "id": "d68a11f1e313adba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not HF_TOKEN:\n",
    "    print (\"No API Key was found \")\n",
    "elif not HF_TOKEN.startswith(\"hf_\"):\n",
    "    print(\"No API Starting With hf_ was found\")\n",
    "else:\n",
    "    print(\"api found\")"
   ],
   "id": "9490aca1b6de241d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not OPENAI_API_KEY:\n",
    "    print (\"No API Key was found \")\n",
    "elif not OPENAI_API_KEY.startswith(\"sk\"):\n",
    "    print(\"No API Starting With hf_ was found\")\n",
    "else:\n",
    "    print(\"api found\")"
   ],
   "id": "ebbbbbb3f3a0c2bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gpt_client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY\n",
    ")"
   ],
   "id": "d19665ed6c9998f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "llama_client = OpenAI(\n",
    "    api_key=HF_TOKEN,\n",
    "    base_url=\"https://router.huggingface.co/v1\"\n",
    ")"
   ],
   "id": "4c29f57928ea66ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "LLAMA_MODEL = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "GPT_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "llama_system = (\n",
    "  \"You are a happy and positive chatbot. \"\n",
    "  \"You look for the good side of things and simple answers. \"\n",
    "  \"Talk like a normal person, not like a professional. \"\n",
    "  \"Keep your replies short and friendly.\"\n",
    ")\n",
    "\n",
    "gpt_system = (\n",
    "  \"You are a negative and doubtful chatbot. \"\n",
    "  \"You focus on problems and what might go wrong. \"\n",
    "  \"Talk like a normal person, not like a professional. \"\n",
    "  \"Keep your replies short and clear.\"\n",
    ")\n",
    "\n",
    "llama_messages = [\"Hi there\"]\n",
    "gpt_messages = [\"Hi\"]\n"
   ],
   "id": "f7e4862428e326f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def call_llama():\n",
    "    messages = [{\"role\": \"system\", \"content\": llama_system}]\n",
    "\n",
    "    for l_msg, g_msg in zip(llama_messages, gpt_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": l_msg})\n",
    "        messages.append({\"role\": \"user\", \"content\": g_msg})\n",
    "\n",
    "    response = llama_client.chat.completions.create(\n",
    "        model=LLAMA_MODEL,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n"
   ],
   "id": "bfb7407dfae82b72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def call_gpt():\n",
    "    messages = [{\"role\": \"system\", \"content\": gpt_system}]\n",
    "\n",
    "    for l_msg, g_msg in zip(llama_messages, gpt_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": l_msg})\n",
    "        messages.append({\"role\": \"user\", \"content\": g_msg})\n",
    "    messages.append({\"role\": \"user\", \"content\": llama_messages[-1]})\n",
    "    response = gpt_client.chat.completions.create(\n",
    "        model=GPT_MODEL,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n"
   ],
   "id": "3675f529be43710e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "TURNS = 5\n",
    "\n",
    "for i in range(TURNS):\n",
    "    llama_reply = call_llama()\n",
    "    llama_messages.append(llama_reply)\n",
    "\n",
    "    gpt_reply = call_gpt()\n",
    "    gpt_messages.append(gpt_reply)\n",
    "\n",
    "    print(f\"\\nðŸ¦™ LLaMA: {llama_reply}\")\n",
    "    print(f\"ðŸ¤– GPT-4o-mini: {gpt_reply}\")\n"
   ],
   "id": "370e007a4d0838e3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
